{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"이 노트북은 개인 공부용 노트북이다.  \n이 노트북에서는 Neural Network의 구축에 대해 저장할 것이다.  \n사용할 데이터는 PTS Nov 2021이다.  \n\n\nLast Update: 21.11.23","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"가장 궁금한 것은 NN의 하이퍼파라미터 튜닝이다. 러닝레이트, 레이어의 개수, 레이어의 크기, 드랍아웃과 배치노멀라이즈 등 조절해야할 파라미터의 수가 너무 많기 때문에\n다른 머신러닝 모델에 비해 튜닝하는 난이도가 훨씬 높다고 생각한다. TPS Nov 2021에서 많은 Vote를 받은 커널들의 저자들의 답변은 아래와 같았다.\n\n1. I had experience with the same from one of my previous competitions and i experimented a bit on the same neural net i changed hidden units based on the results i was receiving in the CV. Most of the part was trial and error\n이전 대회에서도 같은 경험을 했고 실험도 좀 해봤어요.\n같은 신경망에서 CV에서 받은 결과에 따라 숨겨진 단위를 바꿨어요\n대부분은 시행착오였습니다.\n\n2. Hi, I did this by manually tuning the hyperparams and constantly checking with my cv_validation score. Mostly I checked for overfitting (see the graphs in \"Evaluation\")  \n안녕하세요. 저는 수동으로 하이퍼패람을 튜닝하고 지속적으로 cv_validation 점수를 확인하여 이 작업을 수행했습니다. 대부분 과적합 여부를 확인했습니다(\"평가\"의 그래프 참조).\n\n3. There is not trick here just trial and error  \n여기에는 속임수가 없습니다. 시행착오만 있을 뿐.  \n  \n이들의 공통점은 대게 잘 알려진 하이퍼 파라미터들을 사용한 것과 직접 시행착오를 통해 최적화한 것이다. 또한 교차검증을 통해 훈련점수와 검증점수를 모두 기록하고 그래프를 통해 과적합 유무를 확인했다는 것과 과적합이 없는 모델 중 가장 높은 교차점수를 갖는 모델을 선택했다는 것이다. 주어진 훈련데이터를 모두 사용했으며 KFold는 모두 5를 사용했다.","metadata":{}},{"cell_type":"markdown","source":"다음은 은닉층의 크기를 직감적으로 산정할 수 있는 기준 중 하나이다(아직 확실하지 않다).  \nrefer1: https://kugancity.tistory.com/entry/MLP%EC%97%90%EC%84%9C-%EC%A0%81%EC%A0%88%ED%95%9C-hidden-unit-%EA%B0%9C%EC%88%98-%EC%82%B0%EC%A0%95%ED%95%98%EA%B8%B0  \nrefer2: https://m.blog.naver.com/laonple/220576650094  \n  \nManual:  \n이 방법은 경험을 기반으로 좋을 것 같은 파라미터들을 시도해보는 것이다. 아래는 refer1에 언급된 노하우들인데 확실하지 않으므로 참고만 한다.\n1. The number of hidden neurons shold be between the size of the input layer and the size of the output layer.  \n숨겨진 뉴런의 수는 입력층의 크기와 출력층의 크기 사이에 있습니다.\n2. The number of hidden neurons should be 2/3 the size of the input layer, plus the size of the output layer.  \n숨겨진 뉴런의 수는 입력 층의 2/3 크기에 출력 층의 크기를 더해야 합니다.\n3. The number of hidden neurons should be less than twice the size of he input layer.  \n숨겨진 뉴런의 수는 입력층의 두 배 미만이어야 합니다.  \n  \n\nGridSearch:  \nManual과 비슷한 방법인데, 주어진 조합을 모두 수행하는 것이다. Manual과 GridSearch는 validation data가 필요하다.  \n  \nRandomSearch:  \n주어진 범위 내에서 랜덤한 조합을 시도하며, GridSearch보다 빠르게 옵티멀한 조합을 찾는 경향이 있다고 한다.  \n  \nBayesian optimization:  \n탐색 과정에서 얻은 결과를 활용하여 최적값을 찾아가는 방법으로 위 방법들에 비해 효율성을 강조한다.","metadata":{}},{"cell_type":"markdown","source":"## NN Baseline","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\nfrom sklearn.metrics import roc_auc_score\n\nimport tensorflow as tf\nimport tensorflow.keras\nfrom tensorflow.keras import Model, Input\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau","metadata":{"execution":{"iopub.status.busy":"2021-11-23T05:15:37.435959Z","iopub.execute_input":"2021-11-23T05:15:37.436761Z","iopub.status.idle":"2021-11-23T05:15:42.923813Z","shell.execute_reply.started":"2021-11-23T05:15:37.436723Z","shell.execute_reply":"2021-11-23T05:15:42.923001Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-nov-2021/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-nov-2021/test.csv')\nsub = pd.read_csv('../input/tabular-playground-series-nov-2021/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-23T05:15:42.925544Z","iopub.execute_input":"2021-11-23T05:15:42.925814Z","iopub.status.idle":"2021-11-23T05:16:10.792645Z","shell.execute_reply.started":"2021-11-23T05:15:42.925777Z","shell.execute_reply":"2021-11-23T05:16:10.791904Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Data load and Feature Engineering\n\nX_train = train.drop(['id', 'target'], axis=1).copy()\ny_train = train.target\nX_test = test.drop(['id'], axis=1).copy()\n\nscaler = StandardScaler()\nX_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\nX_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T05:16:10.794627Z","iopub.execute_input":"2021-11-23T05:16:10.795121Z","iopub.status.idle":"2021-11-23T05:16:12.891613Z","shell.execute_reply.started":"2021-11-23T05:16:10.795084Z","shell.execute_reply":"2021-11-23T05:16:12.890893Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# callback functions\n\nes = EarlyStopping(\n    monitor='val_loss',\n    patience=20,\n    verbose=0,\n    mode='min',\n    restore_best_weights=True\n)\n\nplateau = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=.2,\n    patience=5,\n    verbose=0,\n    mode='min'\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T05:18:25.302747Z","iopub.execute_input":"2021-11-23T05:18:25.303434Z","iopub.status.idle":"2021-11-23T05:18:25.309334Z","shell.execute_reply.started":"2021-11-23T05:18:25.303395Z","shell.execute_reply":"2021-11-23T05:18:25.308531Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# generate NN model\n\ndef get_model():\n    input_layer = Input(shape=X_test.shape[1], name='input')\n    h1 = Dense(128, activation='swish', name='Dense1')(input_layer)\n    h2 = Dense(64, activation='swish', name='Dense2')(h1)\n    h3 = Dense(32, activation='swish', name='Dense3')(h2)\n    output_layer = Dense(1, activation='sigmoid', name='output')(h3)\n    model = Model(inputs=input_layer, outputs=output_layer, name='baseline')\n    \n    model.compile(\n        optimizer=Adam(learning_rate=1e-4),\n        loss='binary_crossentropy',\n        metrics=['AUC'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-11-23T05:18:26.604558Z","iopub.execute_input":"2021-11-23T05:18:26.605220Z","iopub.status.idle":"2021-11-23T05:18:26.612817Z","shell.execute_reply.started":"2021-11-23T05:18:26.605181Z","shell.execute_reply":"2021-11-23T05:18:26.611927Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"SEED = 42\nBATCH_SIZE = 2048\nEPOCHS = 2000\nVERBOSE = 0","metadata":{"execution":{"iopub.status.busy":"2021-11-23T05:18:27.598668Z","iopub.execute_input":"2021-11-23T05:18:27.599195Z","iopub.status.idle":"2021-11-23T05:18:27.604431Z","shell.execute_reply.started":"2021-11-23T05:18:27.599136Z","shell.execute_reply":"2021-11-23T05:18:27.603762Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\nhistories = {}\nvalid_mean = []\ny_preds = []\nfor i, (train_idx, valid_idx) in enumerate(cv.split(X_train, y_train)):\n    xtrain, xvalid = X_train.iloc[train_idx, :], X_train.iloc[valid_idx, :]\n    ytrain, yvalid = y_train[train_idx], y_train[valid_idx]\n    \n    base_model = get_model()\n    history = base_model.fit(xtrain, ytrain,\n                            validation_data = (xvalid, yvalid),\n                            callbacks=(es, plateau), verbose=VERBOSE,\n                            epochs=EPOCHS, batch_size=BATCH_SIZE)\n    histories[i] = history\n    \n    y_valid_pred  = base_model.predict(xvalid).reshape(1, -1)[0]\n    valid_score = roc_auc_score(yvalid, y_valid_pred)\n    valid_mean.append(valid_score)\n    print('*'*40)\n    print(f'Fold {i + 1} | Traning and Evaluate Validation')\n    print(f'AUC of validation: {valid_score}')\n    print('*'*40+'\\n')\n    \n    y_test_pred = base_model.predict(X_test).reshape(1, -1)[0]\n    y_preds.append(y_test_pred)\nprint('Fold Finished')\nprint(f'AUC MEAN: {np.array(valid_mean).mean()}')\nprint(f'AUC STD: {np.array(valid_mean).std()}')","metadata":{"execution":{"iopub.status.busy":"2021-11-23T05:22:45.601423Z","iopub.execute_input":"2021-11-23T05:22:45.601712Z","iopub.status.idle":"2021-11-23T05:31:21.286403Z","shell.execute_reply.started":"2021-11-23T05:22:45.601667Z","shell.execute_reply":"2021-11-23T05:31:21.284927Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    f, ax = plt.subplots(1, 2, figsize=(20, 3))\n    sns.lineplot(data=histories[i].history['loss'], ax=ax[0], label='train loss')\n    sns.lineplot(data=histories[i].history['val_loss'], ax=ax[0], label='validation loss')\n    sns.lineplot(data=histories[i].history['auc'], ax=ax[1], label='train auc')\n    sns.lineplot(data=histories[i].history['val_auc'], ax=ax[1], label='validation auc')\n    f.suptitle(f'FOLD {i + 1}')","metadata":{"execution":{"iopub.status.busy":"2021-11-23T05:43:56.655340Z","iopub.execute_input":"2021-11-23T05:43:56.655598Z","iopub.status.idle":"2021-11-23T05:43:59.320086Z","shell.execute_reply.started":"2021-11-23T05:43:56.655568Z","shell.execute_reply":"2021-11-23T05:43:59.319260Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# submission\ny_pred = np.mean(np.column_stack(y_preds), axis=1)\nsub.target = y_pred\nsub.to_csv('nn baseline submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T05:46:21.774612Z","iopub.execute_input":"2021-11-23T05:46:21.775010Z","iopub.status.idle":"2021-11-23T05:46:23.153628Z","shell.execute_reply.started":"2021-11-23T05:46:21.774877Z","shell.execute_reply":"2021-11-23T05:46:23.152902Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}